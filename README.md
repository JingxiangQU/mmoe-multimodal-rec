<div align="center">
    <p>
        <a href="#zh-cn">ä¸­æ–‡ç‰ˆ</a> | <a href="#en">English</a>
    </p>
</div>

<div id="zh-cn">

# ç«¯åˆ°ç«¯å¤šæ¨¡æ€MMoEæ¨èç³»ç»Ÿ

[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.x](https://img.shields.io/badge/PyTorch-2.x-orange.svg)](https://pytorch.org/)
[![Apache Beam](https://img.shields.io/badge/Apache%20Beam-2.5x-yellow.svg)](https://beam.apache.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![GitHub stars](https://img.shields.io/github/stars/JingxiangQU/mmoe-multimodal-rec?style=social)](https://github.com/JingxiangQU/mmoe-multimodal-rec)
[![Hugging Face Dataset](https://img.shields.io/badge/ğŸ¤—%20Dataset-jingxiang11111%2Famazon_reviews_for_rec-blue)](https://huggingface.co/datasets/jingxiang11111/amazon_reviews_for_rec)
[![Hugging Face Model](https://img.shields.io/badge/ğŸ¤—%20Model-jingxiang11111%2Fmmoe--multimodal--rec-blue)](https://huggingface.co/jingxiang11111/mmoe-multimodal-rec)
> æœ¬é¡¹ç›®æ˜¯åŸºäº Apache Beam å’Œ PyTorch DDP æ„å»ºçš„ï¼Œä»åŸå§‹æ•°æ®åˆ°æ¨¡å‹è®­ç»ƒçš„ç«¯åˆ°ç«¯å¤šæ¨¡æ€æ¨èç³»ç»Ÿã€‚é¡¹ç›®åŒ…æ‹¬åˆ†å¸ƒå¼ç‰¹å¾å·¥ç¨‹ã€é«˜æ•ˆæ•°æ®åŠ è½½ã€å¤æ‚æ¨¡å‹ï¼ˆMMoEï¼‰çš„åˆ†å¸ƒå¼è®­ç»ƒä¸å¾®è°ƒã€‚
> ç»“æœå±•ç¤ºï¼š<img width="1120" height="575" alt="cc8ddd5d25b25f8829b27353edf78c8" src="https://github.com/user-attachments/assets/b5b95593-963f-4dab-b489-0d7eb43de8db" />
<img width="800" height="600" alt="image" src="https://github.com/user-attachments/assets/27a53ba8-bb8f-4ab0-bc7e-ded8149bf20f" /><img width="800" height="600" alt="image" src="https://github.com/user-attachments/assets/5ccd6ace-a197-403e-b007-ab170bf6e62a" />

-**ç»“æœåˆ†æ**
> ### **ç»“æœåˆ†æ**
> * åœ¨**22,281æ¡**ç‹¬ç«‹éªŒè¯é›†æ ·æœ¬ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå–å¾—äº†å“è¶Šçš„æ€§èƒ½ï¼š
>     * **AUC for 'good' task: 0.938**
>     * **AUC for 'best' task: 0.926**
> * åœ¨`data4moe_beam.py`ä¸­ï¼Œé€šè¿‡`SplitByDate`æ¨¡å—ä¸¥æ ¼æŒ‰ç…§æ—¶é—´åºï¼ˆè®­ç»ƒé›† â‰¤ 2023.6.30 < éªŒè¯é›† â‰¤ 2023.9.30ï¼‰åˆ’åˆ†æ•°æ®é›†ï¼Œæœ‰æ•ˆé˜²æ­¢äº†æ•°æ®ç©¿è¶Šï¼Œç¡®ä¿äº†è¯„ä¼°ç»“æœçš„å…¬æ­£æ€§ã€‚

## æ•°æ®é›†å’Œæ¨¡å‹

æœ¬é¡¹ç›®æ‰€ç”¨çš„**æ•°æ®é›†**å’Œ**è®­ç»ƒå¥½çš„æ¨¡å‹**å‡å·²åœ¨ Hugging Face Hub ä¸Šå¼€æºï¼Œæ–¹ä¾¿ç¤¾åŒºè¿›è¡Œå¤ç°å’Œè¿›ä¸€æ­¥ç ”ç©¶ã€‚
* **å¤‡æ³¨**ï¼š ç”±äºæ–‡ä»¶æ•°é‡è¿‡å¤šï¼Œä»runpodå¹³å°ä¸Šä¼ æ–‡ä»¶åˆ°hugging faceæ—¶è¢«rate limitå¯¼è‡´å¤§é‡æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œä¼šå°½å¿«è§£å†³ã€‚

* **æ•°æ®é›† (Amazon Reviews for Recommendation)**: åŒ…å«äº†ç”¨äºå¤„ç†åçš„ç”¨äºè®­ç»ƒçš„æ•°æ®ç”¨äºéªŒè¯çš„æ•°æ®ã€‚
    [å‰å¾€ Hugging Face æ•°æ®é›†](https://huggingface.co/datasets/jingxiang11111/amazon_reviews_for_rec)

* **æ¨¡å‹ (MMoE Multimodal Recommender)**: è®­ç»ƒå¥½çš„ MMoE æ¨¡å‹æ–‡ä»¶ã€‚
    [å‰å¾€ Hugging Face æ¨¡å‹](https://huggingface.co/jingxiang11111/mmoe-multimodal-rec)


---

## æ ¸å¿ƒç‰¹æ€§

- **ç«¯åˆ°ç«¯å…¨æµç¨‹**: è¦†ç›–ä»æ•°æ®æ‹‰å–ã€å¤„ç†åˆ°æ¨¡å‹è®­ç»ƒçš„å®Œæ•´é—­ç¯ã€‚
- **å¯æ‹“å±•æ¶æ„**: ç‰¹å¾å·¥ç¨‹ä¸æ¨¡å‹è®­ç»ƒå®Œå…¨è§£è€¦ï¼Œæé«˜ç³»ç»Ÿå¯æ‰©å±•æ€§ã€‚
- **é«˜æ€§èƒ½æ•°æ®ç®¡é“**: ä½¿ç”¨ WebDataset å­˜å‚¨ï¼Œè§£å†³äº‘å­˜å‚¨ç¯å¢ƒä¸‹çš„I/Oç“¶é¢ˆã€‚
- **å…ˆè¿›æ¨¡å‹æ¶æ„**: å®ç°å¤æ‚çš„å¤šä»»åŠ¡ä¸“å®¶æ··åˆæ¨¡å‹ (MMoE)ã€‚
- **é«˜æ•ˆåˆ†å¸ƒå¼è®­ç»ƒ**: ä½¿ç”¨ PyTorch DistributedDataParallel (DDP) è®­ç»ƒã€‚

---

## ç³»ç»Ÿæ¶æ„

æœ¬é¡¹ç›®çš„æ ¸å¿ƒè®¾è®¡æ€æƒ³æ˜¯å°†æ•´ä¸ªæ¨èæµç¨‹æ‹†åˆ†ä¸ºä¸¤ä¸ªç‹¬ç«‹ä½†è¡”æ¥çš„é˜¶æ®µï¼š**ç¦»çº¿ç‰¹å¾å·¥ç¨‹** å’Œ **æ¨¡å‹è®­ç»ƒ**ã€‚

```mermaid
graph TD
    %% High-Level Pipeline
    subgraph "Phase 1: Offline Data Engineering (Apache Beam on CPU Cluster)"
        A[Raw Data on Hugging Face] --> B(Data Ingestion Scripts);
        B --> C{GCS Storage: Raw JSONL};
        C --> D[Beam Pipeline 1: data4moe_beam.py];
        D -- Generates --> E[User/Item Features];
        D -- Generates --> F(Image URLs List);
        F --> G[Beam Pipeline 2: newpatch.py];
        G -- Distributed Image Fetching & Patching --> H(Image Patches Data);
        E & H --> I[Beam Pipeline 3: data4model.py];
        I -- Joins Features & Image Patches --> J(Processed Data in WebDataset format on GCS);
    end

    subgraph "Phase 2: Model Training (PyTorch DDP on GPU Cluster)"
        J --> K[WebDataset Loader];
        K --> L(Distributed Training Pipeline: train.py);
        L --> M[Multi-GPU Training with DDP];
        M --> N{MMoE Model};
        N --> O[Multi-Task Prediction];
        O --> P(Saved Checkpoints & Performance Plots);
    end

    %% Detailed MMoE Model Structure
    subgraph "Input Modalities"
        U[User Text] --> P1(preprocess_batch);
        I_text[Item Text] --> P2(preprocess_batch);
        IMG[Item Image Patches] --> IIME(ItemImageExpert);
    end

    subgraph "Text Experts (LoRA Tuned)"
        direction LR
        P1 --> UE(TextExpert: User);
        P2 --> IE(TextExpert: Item);
    end

    subgraph "Expert Feature Extraction"
        UE -- u_doc --> MM1[Expert Vecs Collection];
        IE -- i_doc --> MM1;
        IIME -- img_vec --> MM1;

        UE -- u_sent, u_mask --> RC(RobustTextCrossExpert: Cross-UI Attention);
        IE -- i_sent, i_mask --> RC;
        RC -- ui_vec --> MM1;

        UE -- u_doc --> CUI(EnhancedCrossFuse: User-Image Concat);
        IIME -- img_vec --> CUI;
        CUI -- xui --> MM1;

        IE -- i_doc --> CTI(EnhancedCrossFuse: Item-Image Concat);
        IIME -- img_vec --> CTI;
        CTI -- xti --> MM1;
    end

    subgraph "MMoE Head (TwoTaskMMoE)"
        MM1 --> QH("Query Generation: mean(expert_vecs)");

        QH -- Query --> G1(DenseGate: Task Good);
        QH -- Query --> G2(DenseGate: Task Best);

        G1 -- Weights --> F1(Weighted Sum of Expert Vecs);
        G2 -- Weights --> F2(Weighted Sum of Expert Vecs);

        F1 --> T1(Task Tower: Good);
        F2 --> T2(Task Tower: Best);
    end

    T1 -- Logit --> L_GOOD(Label Good Prediction);
    T2 -- Logit --> L_BEST(Label Best Prediction);

    %% Arrow connecting the detailed view to the high-level block
    T1 --> N;
    T2 --> N;

    %% Styling
    style J fill:#f9f,stroke:#333,stroke-width:2px
    style K fill:#ccf,stroke:#333,stroke-width:2px
    style UE fill:#e0f7fa,stroke:#0097a7,stroke-width:2px
    style IE fill:#e0f7fa,stroke:#0097a7,stroke-width:2px
    style IIME fill:#fffde7,stroke:#ffc107,stroke-width:2px
    style RC fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
    style CUI fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style CTI fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style MM1 fill:#fce4ec,stroke:#d81b60,stroke-width:2px
    style QH fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px
    style G1 fill:#ffebee,stroke:#f44336,stroke-width:2px
    style G2 fill:#ffebee,stroke:#f44336,stroke-width:2px
    style T1 fill:#e1f5fe,stroke:#03a9f4,stroke-width:2px
    style T2 fill:#e1f5fe,stroke:#03a9f4,stroke-width:2px
```
---

## ç‰¹å¾å·¥ç¨‹æ•ˆæœå±•ç¤º

ä»¥ä¸‹æ˜¯ä¸€ä¸ªä»Beamæµæ°´çº¿ä¸­ç”Ÿæˆçš„çœŸå®ç”¨æˆ·ç”»åƒæ ·æœ¬ï¼š

```json
{
  "user_id": "USER_EXAMPLE_ID",
  "user_feat": {
    "cat_hist": {
      "All Electronics": 0.14,
      "Tools & Home Improvement": 0.43,
      "Sports & Outdoors": 0.14
    },
    "review_cnt": 7,
    "price_mean": 25.59,
    "price_std": 25.5,
    "history": [
      {
        "title": "Do not buy...did not work, will not hold a charge.",
        "text": "Purchased in Dec, first charge to full capacity before use mid January in Makita charger that came with drill. Neither battery held a sufficient charge to be useful..."
      },
      {
        "title": "20 amp 250v plug",
        "text": "Sometimes hard to find this 20 amp 250v plug was just what ai needed and I found it on Amazon. Superior Electric had it to me in good time at a fair price."
      }
    ]
  }
}
```

### äº®ç‚¹è§£è¯» (Key Insights)

- **ä¸ºå¥çº§äº¤å‰æ³¨æ„åŠ›èµ‹èƒ½**: ç‰¹å¾å·¥ç¨‹ä¸­æœ‰æ„è¯†åœ°å°†ç”¨æˆ·å¤šæ¡å†å²è¯„è®ºæ•´åˆæˆå®Œæ•´æ–‡æœ¬æ®µè½ã€‚
- **ç²¾å‡†åˆ†å¥ä½œä¸ºæ¡¥æ¢**: æ¨¡å‹è®­ç»ƒé¢„å¤„ç†é˜¶æ®µç²¾å‡†åˆ‡åˆ†æ–‡æœ¬æ®µè½æˆå¥å­ï¼Œå®ç°ç»†ç²’åº¦è¯­ä¹‰ç†è§£ã€‚
- **å®ç°æ·±åº¦è¯­ä¹‰äº¤äº’**: å¥å‘é‡åºåˆ—è¢«é€å…¥äº¤å‰æ³¨æ„åŠ›æ¨¡å—ï¼Œå®ç°ç”¨æˆ·å†å²å…´è¶£å’Œç‰©å“æè¿°é—´çš„æ·±åº¦è¯­ä¹‰äº¤äº’ã€‚

---
## é¡¹ç›®ç»“æ„

```text
.
â”œâ”€â”€ data4moe_beam.py     # ä¸»ç‰¹å¾å·¥ç¨‹è„šæœ¬ (Beam)ï¼Œç”Ÿæˆç”¨æˆ·/ç‰©å“ç‰¹å¾å’Œå›¾ç‰‡URLåˆ—è¡¨ï¼Œ æŒ‰ç…§æ—¥æœŸåˆ’åˆ†train/valid/testï¼Œä¸¥é˜²ç‰¹å¾ç©¿è¶Š
â”œâ”€â”€ newpatch.py          # åˆ†å¸ƒå¼å›¾ç‰‡å¤„ç†è„šæœ¬ (Beam)ï¼Œå°†URLè½¬æ¢ä¸ºå›¾åƒpatchæ•°æ®
â”œâ”€â”€ data4model.py        # åˆå¹¶æ‰€æœ‰ç‰¹å¾å¹¶ç”ŸæˆWebDatasetçš„è„šæœ¬ (Beam)
â”œâ”€â”€ meta2gcs.py          # ä»Hugging Faceä¸‹è½½å…ƒæ•°æ®çš„è¾…åŠ©è„šæœ¬
â”œâ”€â”€ review2gcs.py        # ä»Hugging Faceä¸‹è½½è¯„è®ºæ•°æ®çš„è¾…åŠ©è„šæœ¬
â”œâ”€â”€ model.py             # å®šä¹‰æ‰€æœ‰PyTorchæ¨¡å‹æ¶æ„ (MMoE, Experts)
â”œâ”€â”€ train.py             # æ ¸å¿ƒæ¨¡å‹è®­ç»ƒè„šæœ¬ (PyTorch DDP)
â”œâ”€â”€ inference_and_auc.py # æ¨ç†è„šæœ¬ï¼Œå¹¶è®¡ç®—auc
â”œâ”€â”€ requirements.txt     # é¡¹ç›®ä¾èµ–
â””â”€â”€ README.md            # æœ¬æ–‡æ¡£
```
---
## ç¯å¢ƒå®‰è£…

```shell
git clone [ä½ çš„ä»“åº“URL]
cd [ä½ çš„ä»“åº“ç›®å½•]

conda create -n mmoe_rec python=3.11
conda activate mmoe_rec

pip install -r requirements.txt

python -c "import nltk; nltk.download('punkt'); nltk.download('punkt_tab')"
```

---

## å¦‚ä½•è¿è¡Œ

### æ•°æ®å‡†å¤‡

```shell
python meta2gcs.py --bucket [ä½ çš„GCSæ¡¶åç§°]
python review2gcs.py --bucket [ä½ çš„GCSæ¡¶åç§°]

python data4moe_beam.py --[ç›¸å…³å‚æ•°]
python newpatch.py --[ç›¸å…³å‚æ•°]
python data4model.py --output_dir gs://[ä½ çš„GCSè·¯å¾„]
```

### æ¨¡å‹è®­ç»ƒ

```shell
export TOKENIZERS_PARALLELISM=false

torchrun --nproc_per_node=2 train.py \
  --model_name BAAI/bge-base-en-v1.5 \
  --img_model google/vit-base-patch16-224-in21k \
  --data_pattern '/path/to/your/local/wds_shards/data-*-*.tar.gz' \
  --batch_size 128 \
  --grad_accum 8 \
  --epochs 4 \
  --num_workers 32 \
  --lora_r 8 \
  --lr 1e-5 \
  --output_dir /workspace/outputs
```

---

### æ¨ç†
```shell

python inference_and_auc.py \
  --data_pattern 'valid/data-*-*.tar.gz' \
  --checkpoint_path './outputs/ckpt_epoch3.pt' \
  --output_dir './outputs' \
  --model_name BAAI/bge-base-en-v1.5 \
  --img_model google/vit-base-patch16-224-in21k \
  --batch_size 256 \
  --num_workers 8 \
  --lora_r 8
```

---

## æ€§èƒ½ä¼˜åŒ–ä¸æˆæœ

- **è§£å†³I/Oç“¶é¢ˆ**: æ—©æœŸå®éªŒå‘ç°ï¼Œç›´æ¥ä»GCSæµå¼è¯»å–æ•°æ®å¯¼è‡´ä¸¥é‡çš„I/Oç“¶é¢ˆï¼ŒGPUåˆ©ç”¨ç‡æä½ã€‚é€šè¿‡å°†æ•°æ®é¢„å…ˆä¸‹è½½åˆ°æœ¬åœ°ç£ç›˜ï¼Œå½»åº•è§£å†³äº†è¯¥é—®é¢˜ã€‚
- **ä¼˜åŒ–CPUé¢„å¤„ç†**: spaCyåˆ†è¯å™¨æˆä¸ºæ–°çš„CPUç“¶é¢ˆã€‚é€šè¿‡æ›¿æ¢ä¸ºè½»é‡çº§çš„NLTKåˆ†è¯å™¨ï¼Œæ•°æ®é¢„å¤„ç†é€Ÿåº¦æå‡äº†è¶…è¿‡50å€ï¼Œæ˜¾è‘—æé«˜äº†GPUçš„å¹³å‡åˆ©ç”¨ç‡ã€‚
- **ç²¾ç»†åŒ–æ˜¾å­˜ç®¡ç†**: åœ¨LoRAå¾®è°ƒè§£å†»æ—¶é‡åˆ°äº†åå¤çš„CUDA OOMé—®é¢˜ã€‚é€šè¿‡ç³»ç»Ÿæ€§åœ°ä¸‹è°ƒbatch_sizeã€å¢åŠ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ã€é™åˆ¶max_tokï¼Œæœ€ç»ˆæ‰¾åˆ°äº†ä¸€ä¸ªå¯ä»¥åœ¨80GBæ˜¾å­˜å†…ç¨³å®šè¿è¡Œçš„æœ€ä½³é…ç½®ï¼Œå®ç°äº†é«˜è¾¾91%çš„æ˜¾å­˜åˆ©ç”¨ç‡ã€‚


---
## è®­ç»ƒç»“æœ
<img width="640" height="480" alt="global_step_loss_curve" src="https://github.com/user-attachments/assets/6372e575-8577-4d20-8280-9268df3bdb8b" />
<img width="640" height="480" alt="epoch_interval_loss_curve" src="https://github.com/user-attachments/assets/51c1126e-e913-439f-aec8-05979c3c9cc9" />

- **æ³¨**ï¼šå…±4ä¸ªepochï¼Œå›¾2ä¸­æ¯ä¸ªepoché‡å¤è®¡æ•°äº†ä¸€æ¬¡ï¼Œå·²å®šä½é—®é¢˜å¹¶åœ¨`train.py`ä¸­ä¿®æ”¹ã€‚
  
---

### ç°æœ‰ä¸è¶³

-   **lossæ›²çº¿æ²¡æœ‰ç¨³å®šä¸‹é™**: å½“å‰çš„è®­ç»ƒæŸå¤±æ›²çº¿å¹¶æœªå‘ˆç°ç†æƒ³çš„ç¨³å®šä¸‹é™è¶‹åŠ¿ã€‚åˆæ­¥è¯Šæ–­å’Œè¡ŒåŠ¨è®¡åˆ’å¦‚ä¸‹ï¼š
    * **åˆæ­¥åˆ†æ**:
        * **å­¦ä¹ ç‡é—®é¢˜**: å½“å‰å­¦ä¹ ç‡ï¼ˆå¦‚1e-5ï¼‰å¯èƒ½ç›¸å¯¹è¾ƒé«˜ï¼Œå¯¼è‡´ä¼˜åŒ–è¿‡ç¨‹åœ¨æœ€ä¼˜è§£é™„è¿‘éœ‡è¡æˆ–ç›´æ¥è·³è¿‡ã€‚
        * **Warmupä¸Gateç¨³å®šæ€§**: åˆå§‹åŒ–å‚æ•°çš„Warmupæ­¥æ•°å¯èƒ½ä¸è¶³ï¼Œå¯¼è‡´LoRAå¾®è°ƒå¯åŠ¨æ—¶ï¼ŒMMoEçš„Gateæƒé‡å°šæœªæ”¶æ•›ï¼Œå¯¹ä¸“å®¶çš„é€‰æ‹©ä»å¤„äºä¸ç¨³å®šçŠ¶æ€ï¼Œå½±å“æ¨¡å‹å­¦ä¹ ã€‚
        * **è„æ•°æ®å¹²æ‰°**: è®­ç»ƒæ•°æ®ä¸­æœªèƒ½æˆåŠŸæŠ“å–å›¾ç‰‡çš„æ ·æœ¬è¢«å¤„ç†ä¸ºâ€œå…¨é›¶å›¾ç‰‡â€ï¼Œè¿™éƒ¨åˆ†æ— æ•ˆæ ·æœ¬çš„å æ¯”è¾ƒé«˜ï¼Œå¯èƒ½å¯¼è‡´æ¨¡å‹å­¦åˆ°çš„æ˜¯å™ªå£°è€Œéæœ‰æ•ˆç‰¹å¾ï¼Œä»è€Œäº§ç”Ÿæ¢¯åº¦æ‰°åŠ¨ã€‚
        * **æ•°æ®æµä¸æ”¶æ•›æ€§**: åœ¨æ¯ä¸ªepochéƒ½å¼•å…¥æœªå­¦ä¹ è¿‡çš„æ–°æ ·æœ¬çš„è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œæ¨¡å‹å¯èƒ½éœ€è¦æ›´å¤šçš„è®­ç»ƒæ­¥æ•°æ‰èƒ½åœ¨åºå¤§çš„æ•°æ®ç©ºé—´ä¸Šè¾¾åˆ°å……åˆ†æ”¶æ•›ã€‚

    * **è¡ŒåŠ¨è®¡åˆ’ä¸å®éªŒè®¾è®¡**: é’ˆå¯¹ä»¥ä¸Šå››ä¸ªæ½œåœ¨é—®é¢˜ï¼Œå·²è§„åˆ’ä¸‰ç»„å¹¶è¡Œçš„å¯¹ç…§å®éªŒè¿›è¡Œå®šä½å’ŒéªŒè¯
        * **å®éªŒAï¼ˆå­¦ä¹ ç‡å’ŒWarmupï¼‰**: å›ºå®šå…¶ä»–æ¡ä»¶ï¼Œæµ‹è¯•ä¸‰ç»„å­¦ä¹ ç‡ï¼ˆ1e-5, 5e-6, 1e-6ï¼‰å’Œä¸¤ç»„Warmupæ­¥æ•°ï¼ˆ1000, 3000ï¼‰çš„ç»„åˆã€‚åŒæ—¶ï¼Œå°†è®°å½•Gateå±‚è¾“å‡ºçš„ç†µï¼ˆentropyï¼‰æˆ–æ ‡å‡†å·®ï¼ˆstandard deviationï¼‰ä½œä¸ºå…¶ç¨³å®šæ€§çš„é‡åŒ–ç›‘æ§æŒ‡æ ‡ã€‚
        * **å®éªŒBï¼ˆè„æ•°æ®åˆ†æï¼‰**: ä¿®æ”¹`model.py`ä¸­çš„æ•°æ®åŠ è½½é€»è¾‘ï¼Œç²¾ç¡®ç»Ÿè®¡å¹¶æ‰“å°æ¯ä¸ªepochä¸­â€œå…¨é›¶å›¾ç‰‡â€æ ·æœ¬çš„å æ¯”ã€‚è‹¥æ¯”ä¾‹æ˜¾è‘—ï¼ˆå¦‚ > 5%ï¼‰ï¼Œåˆ™ä¼˜å…ˆä¿®å¤`newpatch.py`ä¸­çš„å›¾ç‰‡è·å–å’Œå¤„ç†é€»è¾‘ï¼›åä¹‹åˆ™æš‚æ—¶æç½®æ­¤é—®é¢˜ã€‚
        * **å®éªŒCï¼ˆæ”¶æ•›æ€§åˆ†æï¼‰**: ä¿æŒç°æœ‰è®­ç»ƒç­–ç•¥ï¼Œä½†å°†æ€»è®­ç»ƒæ­¥æ•°å»¶é•¿50%ï¼Œå¹¶ä»¥æ›´ç»†çš„ç²’åº¦åœ¨ç‹¬ç«‹çš„éªŒè¯é›†ä¸Šè®°å½•AUCæŒ‡æ ‡çš„å˜åŒ–ã€‚é€šè¿‡ç»˜åˆ¶æ›´é•¿çš„å­¦ä¹ æ›²çº¿ï¼Œåˆ¤æ–­æ¨¡å‹æ˜¯å¦å­˜åœ¨æŒç»­æ”¶æ•›çš„æ½œåŠ›ï¼Œå¹¶è¯„ä¼°å½“å‰è®­ç»ƒæ­¥æ•°æ˜¯å¦å……è¶³ã€‚

-   **æ•°æ®æ¸…æ´—é€»è¾‘æœ‰å¾…åŠ å¼º**: å½“å‰åœ¨`data4model.py`ä¸­çš„`normalize_text`å‡½æ•°è™½ç„¶å®ç°äº†ä¸€äº›åŸºç¡€çš„æ–‡æœ¬è§„èŒƒåŒ–ï¼Œä½†å¯¹äºçœŸå®ä¸–ç•Œä¸­æ›´ä¸ºå˜ˆæ‚å’Œéç»“æ„åŒ–çš„æ–‡æœ¬ï¼ˆå¦‚ä¿šè¯­ã€æ‹¼å†™é”™è¯¯ã€ç‰¹æ®Šç¬¦å·ç­‰ï¼‰å¤„ç†èƒ½åŠ›æœ‰é™ï¼Œé€»è¾‘æœ‰å¾…è¿›ä¸€æ­¥åŠ å¼ºã€‚

-   **ç‰¹å¾æ‹¼æ¥æ–¹å¼ç›¸å¯¹ç®€å•**: `data4model.py`ä¸­çš„`build_user_text`å’Œ`build_item_text`å‡½æ•°å°†å¤šæºç‰¹å¾ç›´æ¥æ‹¼æ¥æˆä¸€ä¸ªé•¿å­—ç¬¦ä¸²ã€‚æ²¡æœ‰è€ƒè™‘ç‰¹å¾é—´çš„ç»“æ„åŒ–ä¿¡æ¯ï¼Œå¢åŠ äº†æ¨¡å‹ä»çº¯æ–‡æœ¬ä¸­åˆ†ç¦»å’Œç†è§£ä¸åŒè¯­ä¹‰ä¿¡æ¯çš„è´Ÿæ‹…ã€‚

-   **è®­ç»ƒä¸­ç¼ºå¤±AUCè¯„ä¼°**: `train.py`è„šæœ¬ä¸­ï¼Œç”±äºæ ·æœ¬é‡å·¨å¤§ï¼Œåœ¨æ¯ä¸ªstepåè®¡ç®—AUCè€—æ—¶è¿‡é•¿ï¼Œå› æ­¤å½“å‰çš„è®­ç»ƒè„šæœ¬ä¸­å¹¶æœªåŒ…å«åœ¨çº¿çš„AUCè®¡ç®—ã€‚ è¿™å¯¼è‡´è®­ç»ƒè¿‡ç¨‹ä¸­æ— æ³•å®æ—¶ç›‘æ§æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸‹ä¸€æ­¥è®¡åˆ’æ˜¯åœ¨ç‹¬ç«‹çš„éªŒè¯é›†ä¸Šè¿›è¡Œå®Œæ•´çš„ç¦»çº¿AUCè¯„æµ‹ï¼ˆä¼˜å…ˆåº¦æœ€é«˜ï¼‰ã€‚UPDATEï¼š-**å·²è§£å†³**

### æœªæ¥å·¥ä½œæ–¹å‘

-   **ç¦»çº¿ç‰¹å¾é¢„å¤„ç†**: å°†åˆ†è¯å’ŒTokenizerç¼–ç ç­‰CPUå¯†é›†å‹ä»»åŠ¡å®Œå…¨ç¦»çº¿åŒ–ï¼Œå°†æœ€ç»ˆçš„Token IDå­˜ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ï¼Œè¿›ä¸€æ­¥å‹æ¦¨æ•°æ®åŠ è½½æ€§èƒ½ï¼Œè®©GPUåˆ©ç”¨ç‡è¾¾åˆ°æè‡´ã€‚
-   **æµå¼å¤„ç†**: æ€è€ƒå¦‚ä½•å°†Beamæµæ°´çº¿ä»æ‰¹å¤„ç†æ¨¡å¼åˆ‡æ¢åˆ°æµå¤„ç†æ¨¡å¼ï¼Œå¯¹æ¥å®æ—¶ç”¨æˆ·è¡Œä¸ºæ•°æ®æµï¼Œå®ç°å‡†å®æ—¶çš„ç‰¹å¾æ›´æ–°å’Œæ¨¡å‹è®­ç»ƒã€‚
-   **æ¨¡å‹æ¶æ„æ¢ç´¢**: å°è¯•æ›´å¤æ‚çš„äº¤å‰æ³¨æ„åŠ›ç»“æ„ï¼Œä»¥æ›´å¥½åœ°æ•æ‰å¤šæ¨¡æ€ç‰¹å¾é—´çš„ç»†ç²’åº¦äº¤äº’; åœ¨MMoEä¸­å¼•å…¥ç¨€ç–é—¨æ§æœºåˆ¶ï¼ˆTop-K Gatingï¼‰ã€‚ å—åˆ°è¿‘æœŸå‰æ²¿ç ”ç©¶ï¼ˆå¦‚DeepSeek-V3çš„LFBiasï¼‰çš„å¯å‘ï¼Œæœªæ¥å¯ä»¥æ¢ç´¢æ›´å…ˆè¿›çš„è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼Œä»¥ç¡®ä¿ç¨€ç–é—¨æ§ä¸‹å„ä¸ªä¸“å®¶çš„å‡è¡¡åˆ©ç”¨ï¼Œé˜²æ­¢æ¨¡å‹é€€åŒ–ã€‚


</div>

<div id="en">


# End-to-End Multimodal Recommendation System

[![](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/) [![](https://img.shields.io/badge/PyTorch-2.x-orange.svg)](https://pytorch.org/) [![](https://img.shields.io/badge/Apache%20Beam-2.5x-yellow.svg)](https://beam.apache.org/) [![](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![GitHub stars](https://img.shields.io/github/stars/JingxiangQU/mmoe-multimodal-rec?style=social)](https://github.com/JingxiangQU/mmoe-multimodal-rec)
[![Hugging Face Dataset](https://img.shields.io/badge/ğŸ¤—%20Dataset-jingxiang11111%2Famazon_reviews_for_rec-blue)](https://huggingface.co/datasets/jingxiang11111/amazon_reviews_for_rec)
[![Hugging Face Model](https://img.shields.io/badge/ğŸ¤—%20Model-jingxiang11111%2Fmmoe--multimodal--rec-blue)](https://huggingface.co/jingxiang11111/mmoe-multimodal-rec)

> This project is an end-to-end multimodal recommendation system built with Apache Beam and PyTorch DDP, covering the entire pipeline from raw data to model training. It includes distributed feature engineering, efficient data loading, and distributed training/fine-tuning of a complex Mixture-of-Experts (MMoE) model.
>
> **Results:**
> <img width="1120" height="575" alt="Results Overview" src="https://github.com/user-attachments/assets/b5b95593-963f-4dab-b489-0d7eb43de8db" />
> <img width="800" height="600" alt="ROC Curve for Good Task" src="https://github.com/user-attachments/assets/27a53ba8-bb8f-4ab0-bc7e-ded8149bf20f" /> <img width="800" height="600" alt="ROC Curve for Best Task" src="https://github.com/user-attachments/assets/5ccd6ace-a197-403e-b007-ab170bf6e62a" />
>
> ---
> ### **Result Analysis**
> * Achieved excellent performance on an independent validation set of **22,281 samples**:
>     * **AUC for 'good' task: 0.938**
>     * **AUC for 'best' task: 0.926**
> * The dataset was strictly split by timestamp (train â‰¤ 2023-06-30 < valid â‰¤ 2023-09-30) in the `SplitByDate` module of `data4moe_beam.py` to prevent data leakage and ensure a fair evaluation.

---

## Dataset and Model

The **dataset** and **pre-trained model** used in this project are open-sourced on the Hugging Face Hub to facilitate reproducibility and further research.

* **Dataset (Amazon Reviews for Recommendation)**: Contains the processed data for training and validation.
    [Go to Hugging Face Dataset](https://huggingface.co/datasets/jingxiang11111/amazon_reviews_for_rec)

* **Model (MMoE Multimodal Recommender)**: The trained MMoE model files.
    [Go to Hugging Face Model](https://huggingface.co/jingxiang11111/mmoe-multimodal-rec)
    
* **Note**: Due to rate limits during the upload from the cloud platform, some files may be missing. This will be fixed soon.

---

## Core Features

-   **End-to-End Pipeline**: Covers the complete loop from data ingestion and processing to model training and evaluation.
-   **Scalable Architecture**: Decouples feature engineering from model training for enhanced system scalability.
-   **High-Performance Data Pipeline**: Uses WebDataset to address I/O bottlenecks in cloud storage environments.
-   **Advanced Model Architecture**: Implements a complex Multi-gate Mixture-of-Experts (MMoE) model for multi-task learning.
-   **Efficient Distributed Training**: Employs PyTorch DistributedDataParallel (DDP) for multi-GPU training.

---

## System Architecture

The core design philosophy is to separate the entire recommendation workflow into two independent yet connected stages: **Offline Feature Engineering** and **Model Training**.

```mermaid
graph TD
    %% High-Level Pipeline
    subgraph "Phase 1: Offline Data Engineering (Apache Beam on CPU Cluster)"
        A[Raw Data on Hugging Face] --> B(Data Ingestion Scripts);
        B --> C{GCS Storage: Raw JSONL};
        C --> D[Beam Pipeline 1: data4moe_beam.py];
        D -- Generates --> E[User/Item Features];
        D -- Generates --> F(Image URLs List);
        F --> G[Beam Pipeline 2: newpatch.py];
        G -- Distributed Image Fetching & Patching --> H(Image Patches Data);
        E & H --> I[Beam Pipeline 3: data4model.py];
        I -- Joins Features & Image Patches --> J(Processed Data in WebDataset format on GCS);
    end

    subgraph "Phase 2: Model Training (PyTorch DDP on GPU Cluster)"
        J --> K[WebDataset Loader];
        K --> L(Distributed Training Pipeline: train.py);
        L --> M[Multi-GPU Training with DDP];
        M --> N{MMoE Model};
        N --> O[Multi-Task Prediction];
        O --> P(Saved Checkpoints & Performance Plots);
    end

    %% Detailed MMoE Model Structure
    subgraph "Input Modalities"
        U[User Text] --> P1(preprocess_batch);
        I_text[Item Text] --> P2(preprocess_batch);
        IMG[Item Image Patches] --> IIME(ItemImageExpert);
    end

    subgraph "Text Experts (LoRA Tuned)"
        direction LR
        P1 --> UE(TextExpert: User);
        P2 --> IE(TextExpert: Item);
    end

    subgraph "Expert Feature Extraction"
        UE -- u_doc --> MM1[Expert Vecs Collection];
        IE -- i_doc --> MM1;
        IIME -- img_vec --> MM1;

        UE -- u_sent, u_mask --> RC(RobustTextCrossExpert: Cross-UI Attention);
        IE -- i_sent, i_mask --> RC;
        RC -- ui_vec --> MM1;

        UE -- u_doc --> CUI(EnhancedCrossFuse: User-Image Concat);
        IIME -- img_vec --> CUI;
        CUI -- xui --> MM1;

        IE -- i_doc --> CTI(EnhancedCrossFuse: Item-Image Concat);
        IIME -- img_vec --> CTI;
        CTI -- xti --> MM1;
    end

    subgraph "MMoE Head (TwoTaskMMoE)"
        MM1 --> QH("Query Generation: mean(expert_vecs)");

        QH -- Query --> G1(DenseGate: Task Good);
        QH -- Query --> G2(DenseGate: Task Best);

        G1 -- Weights --> F1(Weighted Sum of Expert Vecs);
        G2 -- Weights --> F2(Weighted Sum of Expert Vecs);

        F1 --> T1(Task Tower: Good);
        F2 --> T2(Task Tower: Best);
    end

    T1 -- Logit --> L_GOOD(Label Good Prediction);
    T2 -- Logit --> L_BEST(Label Best Prediction);

    %% Arrow connecting the detailed view to the high-level block
    T1 --> N;
    T2 --> N;

    %% Styling
    style J fill:#f9f,stroke:#333,stroke-width:2px
    style K fill:#ccf,stroke:#333,stroke-width:2px
    style UE fill:#e0f7fa,stroke:#0097a7,stroke-width:2px
    style IE fill:#e0f7fa,stroke:#0097a7,stroke-width:2px
    style IIME fill:#fffde7,stroke:#ffc107,stroke-width:2px
    style RC fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
    style CUI fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style CTI fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style MM1 fill:#fce4ec,stroke:#d81b60,stroke-width:2px
    style QH fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px
    style G1 fill:#ffebee,stroke:#f44336,stroke-width:2px
    style G2 fill:#ffebee,stroke:#f44336,stroke-width:2px
    style T1 fill:#e1f5fe,stroke:#03a9f4,stroke-width:2px
    style T2 fill:#e1f5fe,stroke:#03a9f4,stroke-width:2px
```
---

## Feature Engineering Showcase

Below is a sample user profile generated from the Beam pipeline:

```json
{
  "user_id": "USER_EXAMPLE_ID",
  "user_feat": {
    "cat_hist": {
      "All Electronics": 0.14,
      "Tools & Home Improvement": 0.43,
      "Sports & Outdoors": 0.14
    },
    "review_cnt": 7,
    "price_mean": 25.59,
    "price_std": 25.5,
    "history": [
      {
        "title": "Do not buy...did not work, will not hold a charge.",
        "text": "Purchased in Dec, first charge to full capacity before use mid January in Makita charger that came with drill. Neither battery held a sufficient charge to be useful..."
      },
      {
        "title": "20 amp 250v plug",
        "text": "Sometimes hard to find this 20 amp 250v plug was just what ai needed and I found it on Amazon. Superior Electric had it to me in good time at a fair price."
      }
    ]
  }
}
```
### Key Insights

- **Enabling Sentence-Level Cross-Attention**: User historical reviews are deliberately aggregated into complete text paragraphs during feature engineering.
- **Precise Sentence Splitting as a Bridge**: The text paragraphs are accurately split into sentences during the model preprocessing stage to enable fine-grained semantic understanding.
- **Achieving Deep Semantic Interaction**: The resulting sentence vector sequences are fed into a cross-attention module to achieve deep semantic interaction between user historical interests and item descriptions.

---
## Project Structure

```text
.
â”œâ”€â”€ data4moe_beam.py     # Main feature engineering script (Beam), prevents data leakage
â”œâ”€â”€ newpatch.py          # Distributed image processing script (Beam)
â”œâ”€â”€ data4model.py        # Script to merge features and generate WebDataset
â”œâ”€â”€ meta2gcs.py          # Helper script to download metadata
â”œâ”€â”€ review2gcs.py        # Helper script to download review data
â”œâ”€â”€ model.py             # Defines all PyTorch model architectures (MMoE, Experts)
â”œâ”€â”€ train.py             # Core model training script (PyTorch DDP)
â”œâ”€â”€ inference_and_auc.py # Inference script to calculate AUC and plot ROC curves
â”œâ”€â”€ requirements.txt     # Project dependencies
â””â”€â”€ README.md            # This document
```
---
## Environment Setup

```shell
git clone [https://github.com/JingxiangQU/mmoe-multimodal-rec.git](https://github.com/JingxiangQU/mmoe-multimodal-rec.git)
cd mmoe-multimodal-rec

# Recommended to use conda
conda create -n mmoe_rec python=3.11
conda activate mmoe_rec

pip install -r requirements.txt

# Download NLTK sentence tokenizer model
python -c "import nltk; nltk.download('punkt');"
```

---

## How to Run

### Data Preparation

```shell
# 1. Download raw data (requires Hugging Face Token environment variable)
python meta2gcs.py --bucket [YOUR_GCS_BUCKET_NAME]
python review2gcs.py --bucket [YOUR_GCS_BUCKET_NAME]

# 2. Run Beam data processing pipelines
python data4moe_beam.py --[RELEVANT_ARGS]
python newpatch.py --[RELEVANT_ARGS]
python data4model.py --output_dir gs://[YOUR_GCS_PATH]
```

### Model Training

```shell
export TOKENIZERS_PARALLELISM=false

torchrun --nproc_per_node=2 train.py \
  --model_name BAAI/bge-base-en-v1.5 \
  --img_model google/vit-base-patch16-224-in21k \
  --data_pattern '/path/to/your/local/wds_shards/data-*-*.tar.gz' \
  --batch_size 128 \
  --grad_accum 8 \
  --epochs 4 \
  --num_workers 32 \
  --lora_r 8 \
  --lr 1e-5 \
  --output_dir /workspace/outputs
```

---

### Inference & Evaluation
```shell

python inference_and_auc.py \
  --data_pattern 'valid/data-*-*.tar.gz' \
  --checkpoint_path './outputs/ckpt_epoch3.pt' \
  --output_dir './outputs' \
  --model_name BAAI/bge-base-en-v1.5 \
  --img_model google/vit-base-patch16-224-in21k \
  --batch_size 256 \
  --num_workers 8 \
  --lora_r 8
```

---

## Performance Optimization & Achievements


-   **Solved I/O Bottleneck**: Initial experiments showed that streaming data directly from GCS caused severe I/O bottlenecks, leading to extremely low GPU utilization. This was resolved by pre-downloading the data to local disk.
-   **Optimized CPU Preprocessing**: The spaCy tokenizer became the new CPU bottleneck. By replacing it with the lightweight NLTK tokenizer, data preprocessing speed was improved by over 50x, significantly increasing average GPU utilization.
-   **Fine-tuned Memory Management**: Encountered recurrent CUDA OOM issues when unfreezing LoRA layers. A stable configuration that runs within 80GB of VRAM was found by systematically reducing `batch_size`, increasing gradient accumulation steps, and limiting `max_tok`, achieving up to 91% VRAM utilization.


---
## Training Results
<img width="640" height="480" alt="global_step_loss_curve" src="https://github.com/user-attachments/assets/6372e575-8577-4d20-8280-9268df3bdb8b" />
<img width="640" height="480" alt="epoch_interval_loss_curve" src="https://github.com/user-attachments/assets/51c1126e-e913-439f-aec8-05979c3c9cc9" />

- **Note**ï¼šThe plotting logic for Figure 2 had a bug that caused each epoch to be double-counted. This has been fixed in `train.py`.
  
---

## Current Limitations & Future Work

### Current Limitations

-   **Unstable Loss Curve**: The training loss curve does not show a steady decrease. A detailed diagnosis and action plan have been formulated:
    * **Initial Analysis**:
        * **Learning Rate**: The current learning rate (e.g., 1e-5) might be too high, causing the optimization to oscillate around the minimum.
        * **Warmup & Gate Stability**: The number of warmup steps might be insufficient, causing the MMoE gates to be unstable when LoRA fine-tuning begins.
        * **Noisy Data**: Samples where image fetching failed are replaced with "zero-tensors," which might introduce gradient noise.
        * **Data Stream & Convergence**: Training on a massive, non-repeating data stream may require more steps to achieve full convergence.
    * **Action Plan & Experiment Design**: A set of three parallel, controlled experiments have been designed to pinpoint the cause:
        * **Experiment A (Learning Rate & Warmup)**: Test combinations of three learning rates (1e-5, 5e-6, 1e-6) and two warmup step counts (1000, 3000), while monitoring the entropy of the gate outputs to quantify stability.
        * **Experiment B (Noisy Data Analysis)**: Modify the data loading logic in `model.py` to accurately count the proportion of "zero-image" samples per epoch. If the ratio is significant (>5%), prioritize fixing the image fetching logic in `newpatch.py`.
        * **Experiment C (Convergence Analysis)**: Extend the total number of training steps by 50% and record validation AUC at a finer granularity to plot a longer learning curve, assessing the model's potential for continued convergence.

-   **Data Cleaning Needs Enhancement**: The `normalize_text` function in `data4model.py` implements basic text normalization but has limited capability in handling noisier, unstructured text found in the real world (e.g., slang, typos).

-   **Simple Feature Concatenation**: The `build_user_text` and `build_item_text` functions in `data4model.py` concatenate multi-source features into a single long string. This approach may lose structural information between features, increasing the model's burden to disentangle and understand different semantics from plain text.

-   **Missing In-Training AUC Evaluation**: The `train.py` script currently lacks online AUC calculation due to the significant time cost on the large dataset. This prevents real-time monitoring of the model's generalization ability. The immediate next step is to implement a full offline AUC evaluation on the validation set. **UPDATE: Resolved.**

### Future Work

-   **Offline Feature Preprocessing**: Move CPU-intensive tasks like tokenization and encoding completely offline, storing the final Token IDs as binary files to maximize data loading performance and GPU utilization.
-   **Stream Processing**: Investigate migrating the Beam pipeline from batch to streaming mode to process real-time user behavior data (e.g., from Kafka) for near-real-time feature updates and model training.
-   **Model Architecture Exploration**: Experiment with more complex cross-attention structures to better capture fine-grained interactions between modalities; introduce sparse gating mechanisms (Top-K Gating) in the MMoE. Inspired by recent research (e.g., LFBias in DeepSeek-V3), explore advanced load-balancing strategies to ensure balanced expert utilization and prevent model degradation.


</div>
